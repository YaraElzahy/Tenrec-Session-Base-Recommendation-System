{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r35_eppo2-Rw"
      },
      "source": [
        "# CISC-839 Data Analytics Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1xBo13v2-Rz"
      },
      "source": [
        "## A Session Based - Recommendation System\n",
        "\n",
        "This Sysyem is a session-based recommendation system, powered by the Ternec dataset. Leveraging the [Tenrec: A Large-scale Multipurpose Benchmark Dataset for Recommender Systems](https://proceedings.neurips.cc/paper_files/paper/2022/file/4ad4fc1528374422dd7a69dea9e72948-Paper-Datasets_and_Benchmarks.pdf) Paper, we aim to deliver personalized recommendations that adapt to users' session-specific preferences in real-time. Join us as we revolutionize the way users discover content by harnessing the power of session-based modeling and the rich insights provided by the Ternec dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70koxp542-Rz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGvdffcr2-R0"
      },
      "source": [
        "## Team Members\n",
        "- Adham Mokhtar\n",
        "- Manar El-Ghobashy\n",
        "- Yara Hassan\n",
        "- Yara El-Zahy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncneL4c62-R0"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, we will explore and analyze the performance of our best session-based recommendation model. We selected the NextItNet model as it outperformed other candidate models, including GRU4Rec, BERT4Rec, and SASRec, based on the NDCG@20 evaluation metric. Our comparison was conducted on two distinct datasets: one containing users with age 3 and the other with users having age 0.\n",
        "\n",
        "The evaluation results for each model on both user groups are as follows:\n",
        "| Model | NDCG@20 for users with age 3 | NDCG@20 for users with age 0 |\n",
        "| --- | --- | ---|\n",
        "| NextItNet| 0.0111 | 0.0081 |\n",
        "| SASRec | 0.0103 | 0.0079 |\n",
        "| GRU4Rec | 0.0100 | 0.0058 |\n",
        "| BERTModel | 7.7849e-05 | 1.1388e-05 |\n",
        "\n",
        "From the comparison, it is evident that the NextItNet model consistently outperformed the other models on both user groups, showcasing its ability to capture sequential patterns effectively for session-based recommendation tasks.\n",
        "\n",
        "We will delve into a detailed discussion of the NextItNet model's performance on both users' groups together, focusing on its strengths and limitations. Additionally, we will assess the model's ability to generalize across different datasets, as it was trained and evaluated on two distinct age groups.\n",
        "\n",
        "To validate the model's generalization, we will further test its performance on a separate test dataset, combining interactions from both age groups. This will provide insights into how well the NextItNet model adapts to unseen data, showcasing its robustness and transferability.\n",
        "\n",
        "Through our analysis, we aim to gain a comprehensive understanding of the NextItNet model's capabilities and uncover any potential challenges it might encounter in real-world scenarios. By comprehensively evaluating the model's performance and generalization abilities, we can make informed decisions about its applicability in various recommendation systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2lt11vw2-R3"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fphn0FjI2-R3"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "# Import the NextItNet model from the custom module 'model.nextitnet'\n",
        "from model.nextitnet import NextItNet\n",
        "\n",
        "# Import the SummaryWriter class from torch.utils.tensorboard for logging\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Import other utility functions and modules\n",
        "from utils import *\n",
        "from trainer import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3KgR_xc62-R4"
      },
      "outputs": [],
      "source": [
        "# Set the random seed to 22\n",
        "seed = 22\n",
        "\n",
        "# Seed the random number generator for Python's built-in 'random' module\n",
        "random.seed(seed)\n",
        "\n",
        "# Set the seed for the hash value generated by Python's hash function (used for dictionaries, sets, etc.)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "# Seed the random number generator for NumPy library\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Seed the random number generator for PyTorch on the CPU\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Seed the random number generator for PyTorch on the GPU (CUDA)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Turn off GPU-specific optimizations that may introduce variability in the results\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a SummaryWriter instance for logging with TensorBoard\n",
        "writer = SummaryWriter()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g439cj3K2-R5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZhHy9Y2-R5"
      },
      "source": [
        "## Data Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "FwR6MYSN2-R5",
        "outputId": "23667405-d8d3-4ea9-c2fc-6c7c0d2407f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adham\\AppData\\Local\\Temp\\ipykernel_17132\\4111369473.py:2: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('sbr_data_1M.csv')\n"
          ]
        }
      ],
      "source": [
        "# Read data from the CSV file 'sbr_data_1M.csv' and store it in a DataFrame\n",
        "data = pd.read_csv('sbr_data_1M.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Kyk5Hll92-R5",
        "outputId": "176db113-8e3f-4c63-940d-0cc92e463df1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>click</th>\n",
              "      <th>follow</th>\n",
              "      <th>like</th>\n",
              "      <th>share</th>\n",
              "      <th>video_category</th>\n",
              "      <th>watching_times</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>80936</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>781</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  click  follow  like  share video_category  \\\n",
              "0        1        1      1       0     0      0              1   \n",
              "1        1        2      1       0     0      0              1   \n",
              "2        1        3      1       0     0      0              0   \n",
              "3        1    80936      1       0     0      0              1   \n",
              "4        1      781      1       0     0      0              1   \n",
              "\n",
              "   watching_times  gender  age  \n",
              "0               1       1    4  \n",
              "1               1       1    4  \n",
              "2               1       1    4  \n",
              "3               1       1    4  \n",
              "4               1       1    4  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 5 rows of the DataFrame 'data'\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU6lYjf02-R6",
        "outputId": "8f765546-ad20-4658-9d52-acfe824da6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38300254 entries, 0 to 38300253\n",
            "Data columns (total 10 columns):\n",
            " #   Column          Dtype \n",
            "---  ------          ----- \n",
            " 0   user_id         int64 \n",
            " 1   item_id         int64 \n",
            " 2   click           int64 \n",
            " 3   follow          int64 \n",
            " 4   like            int64 \n",
            " 5   share           int64 \n",
            " 6   video_category  object\n",
            " 7   watching_times  int64 \n",
            " 8   gender          int64 \n",
            " 9   age             int64 \n",
            "dtypes: int64(9), object(1)\n",
            "memory usage: 2.9+ GB\n"
          ]
        }
      ],
      "source": [
        "# Display a concise summary of the DataFrame 'data'\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_ls-ZP2-R6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye6TqlTE2-R6"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reason for dropping columns:\n",
        "\n",
        "#### 1. Session-based Recommendation System:\n",
        "    The code is preparing the data for a session-based recommendation system. In this context, the focus is on predicting user-item interactions within a session, and the other columns such as 'click', 'follow', 'like', and 'share' might not be relevant for session-level recommendations.\n",
        "\n",
        "#### 2. Model Training:\n",
        "    The code intends to train the recommendation model using only the 'user_id' and 'item_id' columns. These columns represent the essential information required for session-based recommendation, where the goal is to predict which items a user might interact with in the current session.\n",
        "\n",
        "#### 3. Filtering Data Based on Age:\n",
        "    The 'age' column is retained in the DataFrame because it is used for filtering the data. By keeping the 'age' column, the code ensures that only data points corresponding to a specific age group are considered for the session-based recommendation task. It helps tailor the recommendation system to cater to specific user age groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop specified columns from the DataFrame 'data'\n",
        "data.drop(columns=['click', 'follow', 'like', 'share', 'video_category', 'watching_times', 'gender'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO6adL6H2-R8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We are preparing a subset of the data for testing the generalization of the session-based recommendation model.\n",
        "- We select users with age values of 0 and 3, as they have similar record counts, user counts, and item counts to be away of data bias.\n",
        "- Due to GPU resource limitations and previous training failures on Colab and the university server, we are restricting the dataset to one million records\n",
        "- This filtered data will be used to evaluate the model's performance and assess if it can maintain a high value of NDCG@20 (Normalized Discounted Cumulative Gain at top-20) on this combination of age groups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K34OnFkgyyEl",
        "outputId": "88abb473-44c0-4834-e6ea-1e024f37554b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>8</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>8</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>8</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>8</td>\n",
              "      <td>400846</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864889</th>\n",
              "      <td>40320</td>\n",
              "      <td>7369</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864890</th>\n",
              "      <td>40320</td>\n",
              "      <td>2370</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864891</th>\n",
              "      <td>40320</td>\n",
              "      <td>47447</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864892</th>\n",
              "      <td>40320</td>\n",
              "      <td>39866</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864893</th>\n",
              "      <td>40320</td>\n",
              "      <td>117759</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id  item_id  age\n",
              "247            8       97    0\n",
              "248            8       98    0\n",
              "249            8       99    0\n",
              "250            8      106    0\n",
              "251            8   400846    0\n",
              "...          ...      ...  ...\n",
              "1864889    40320     7369    3\n",
              "1864890    40320     2370    3\n",
              "1864891    40320    47447    3\n",
              "1864892    40320    39866    3\n",
              "1864893    40320   117759    3\n",
              "\n",
              "[1000000 rows x 3 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter the DataFrame to include only rows where age is either 0 or 3\n",
        "result_data = data[(data['age'] == 3) | (data['age'] == 0)][0:1000000]\n",
        "\n",
        "# Display the resulting DataFrame 'result_data'\n",
        "result_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bRnSxcvH1qNL"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>8</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>8</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>8</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>8</td>\n",
              "      <td>400846</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  item_id  age\n",
              "247        8       97    0\n",
              "248        8       98    0\n",
              "249        8       99    0\n",
              "250        8      106    0\n",
              "251        8   400846    0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2dL_fpIe1r92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1864889</th>\n",
              "      <td>40320</td>\n",
              "      <td>7369</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864890</th>\n",
              "      <td>40320</td>\n",
              "      <td>2370</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864891</th>\n",
              "      <td>40320</td>\n",
              "      <td>47447</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864892</th>\n",
              "      <td>40320</td>\n",
              "      <td>39866</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1864893</th>\n",
              "      <td>40320</td>\n",
              "      <td>117759</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id  item_id  age\n",
              "1864889    40320     7369    3\n",
              "1864890    40320     2370    3\n",
              "1864891    40320    47447    3\n",
              "1864892    40320    39866    3\n",
              "1864893    40320   117759    3"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Free up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ta1xXSnAz8df"
      },
      "outputs": [],
      "source": [
        "# Delete the variable 'data' from memory to free up resources.\n",
        "# This step is performed to ensure efficient memory management, especially when working with large datasets.\n",
        "# Since we have already created a subset of the data in 'result_data' for the current analysis,\n",
        "# we can safely delete the original DataFrame 'data' to release the memory it occupied.\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4KH5HQDlSDb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sessions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9APKj7KU2-R-",
        "outputId": "904a51c9-370a-493d-e54d-cd964c7af21d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "216555"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the number of unique items\n",
        "num_items = result_data['item_id'].nunique()\n",
        "\n",
        "# Display the number of unique items\n",
        "num_items\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of users"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCaDjT5N2-R-",
        "outputId": "0c51f0cf-994e-480d-f9b4-cfdbb23d0c13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20707"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate the number of unique users\n",
        "num_users = result_data['user_id'].nunique()\n",
        "\n",
        "# Display the number of unique users\n",
        "num_users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbacUYT52-R_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDFRptVX2-SA"
      },
      "source": [
        "## Session Representation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLk_t9Hd2-SA"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The reason for using label encoding is that the 'item_id' column contains gaps between these IDs.\n",
        "- Label encoding is a suitable choice in this case to represent the 'item_id' values in a compact and sequential manner.\n",
        "- This approach helps in making the data representation more realistic, and it is particularly useful when working with categorical or nominal data where there is no intrinsic ordinal relationship between the categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M0hvx8qv2-SA"
      },
      "outputs": [],
      "source": [
        "# Create a label encoding mapping for the item ids\n",
        "# The label encoding will assign unique integers to each unique 'item_id', starting from 1\n",
        "itemIdMapping = {k: i + 1 for i, k in enumerate(sorted(list(result_data['item_id'].unique())))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zTluGfcI2-SA"
      },
      "outputs": [],
      "source": [
        "# Create a new column 'item_id_mapped' by mapping the original 'item_id' values to their label encoded equivalents.\n",
        "result_data[\"item_id_mapped\"] = result_data['item_id'].map(itemIdMapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LvgCr2p72-SA",
        "outputId": "60980103-030b-43e5-9209-f9a1efec56a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>age</th>\n",
              "      <th>item_id_mapped</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>8</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>8</td>\n",
              "      <td>98</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>8</td>\n",
              "      <td>99</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>8</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>8</td>\n",
              "      <td>400846</td>\n",
              "      <td>0</td>\n",
              "      <td>128961</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  item_id  age  item_id_mapped\n",
              "247        8       97    0              84\n",
              "248        8       98    0              85\n",
              "249        8       99    0              86\n",
              "250        8      106    0              92\n",
              "251        8   400846    0          128961"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 5 rows of the DataFrame 'result_data'\n",
        "result_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg3HRJlc2-SA"
      },
      "source": [
        "### Session Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- This operation effectively organizes the data into sessions based on user interactions.\n",
        "- Each session represents a sequence of items (represented by their label encoded integers) that a user has interacted with, and these sequences are grouped according to each user's session.\n",
        "- The 'sessions' DataFrame will be useful for building and training session-based recommendation models that leverage the sequential patterns of user-item interactions for personalized recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7empP3RZ2-SA"
      },
      "outputs": [],
      "source": [
        "# Group the DataFrame 'result_data' by 'user_id' and aggregate the corresponding 'item_id_mapped' values into lists.\n",
        "# Each session corresponds to a user, and the 'item_id_mapped' values for that user are collected in a list.\n",
        "# The resulting DataFrame 'sessions' will have each user_id as the index and a list of corresponding 'item_id_mapped' values as the 'item_id_mapped' column.\n",
        "\n",
        "sessions = result_data.groupby(\"user_id\")[['item_id_mapped']].agg(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "u2I2zwlp2-SA",
        "outputId": "6957502f-355c-4bfa-9b05-b33e05849e08"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id_mapped</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[84, 85, 86, 92, 128961, 17454, 120640, 10840,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[101, 102, 103, 104, 105, 106, 107, 108, 109, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[117, 118, 119, 120, 121, 122, 123, 124, 125, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[169, 170, 171, 172, 174, 175, 176, 2819, 3131...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[205, 206, 207, 208, 209, 210, 211, 214, 218, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            item_id_mapped\n",
              "user_id                                                   \n",
              "8        [84, 85, 86, 92, 128961, 17454, 120640, 10840,...\n",
              "10       [101, 102, 103, 104, 105, 106, 107, 108, 109, ...\n",
              "11       [117, 118, 119, 120, 121, 122, 123, 124, 125, ...\n",
              "14       [169, 170, 171, 172, 174, 175, 176, 2819, 3131...\n",
              "17       [205, 206, 207, 208, 209, 210, 211, 214, 218, ..."
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 5 rows of the DataFrame 'sessions'\n",
        "sessions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DUJD13V2-SA"
      },
      "source": [
        "### Session Length Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AnZqt9dr2-SB"
      },
      "outputs": [],
      "source": [
        "# Define the minimum and maximum sequence lengths for session-based recommendation based on the paper.\n",
        "\n",
        "# Minimum Sequence Length:\n",
        "# The 'min_sequence_length' variable is set to 10, which specifies the minimum number of items required in a session (user's interaction sequence).\n",
        "# Sessions with fewer than 10 items may be excluded from the analysis to ensure that sessions used for training have a minimum length to capture meaningful patterns.\n",
        "\n",
        "min_sequence_length = 10\n",
        "\n",
        "# Maximum Sequence Length:\n",
        "# The 'max_sequence_length' variable is set to 30, which represents the maximum allowed number of items in a session (user's interaction sequence).\n",
        "# Sessions with more than 30 items may be truncated to this maximum length to avoid excessively long sequences, ensuring computational efficiency during training.\n",
        "\n",
        "max_sequence_length = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5sZNpJbR2-SB"
      },
      "outputs": [],
      "source": [
        "# Filter the 'sessions' DataFrame to include only sessions with a length greater than the 10.\n",
        "sessions = sessions[sessions['item_id_mapped'].apply(lambda x: len(x) > min_sequence_length)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jpG1Q9sH2-SB"
      },
      "outputs": [],
      "source": [
        "# Filter the 'sessions' DataFrame to include only sessions with a length less than the 30.\n",
        "sessions['item_id_mapped'] = sessions['item_id_mapped'].apply(lambda x: x[:max_sequence_length])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXTbFHsW2-SB",
        "outputId": "2cd58987-8e57-4482-de4e-9c1cc06a0e9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([list([84, 85, 86, 92, 128961, 17454, 120640, 10840, 2268, 5725, 1797, 3938, 27621, 512, 13002, 10746, 29522, 43901, 17783, 6091, 17511, 136868, 67751, 15444, 1585, 28732, 4887, 98, 1349, 21736]),\n",
              "       list([101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 113, 115, 128340, 128341, 128342, 141511, 141512, 141513, 12727, 147335, 147336, 150573, 6066, 152681, 152682, 152683, 5275, 111235, 120537, 162758]),\n",
              "       list([117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 133, 134, 135, 672, 850, 3815, 104632, 3679, 9699, 605, 11205, 17535, 1491, 11317, 5988, 3850, 1117]),\n",
              "       ...,\n",
              "       list([15154, 56115, 1183, 1300, 11951, 23993, 27274, 17397, 1364, 89658, 2103, 32370, 6880, 10620, 8847, 78703, 2602]),\n",
              "       list([24978, 24978, 24978, 8477, 17386, 2520, 3933, 128845, 24978, 2567, 118161, 5823, 8939, 151387, 1883, 1628, 9743, 6821, 7242, 3103, 78, 2111, 3742]),\n",
              "       list([806, 74388, 81633, 8622, 3905, 680, 948, 13634, 11303, 3750, 21783, 5915, 1910, 33222, 28453, 72093])],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the 'item_id_mapped' values.\n",
        "sessions['item_id_mapped'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzBZfu5p2-SB"
      },
      "source": [
        "### Session Padding\n",
        "add padding to the beginning of each sequance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "F9-k3OUZ2-SB"
      },
      "outputs": [],
      "source": [
        "# Pad the 'item_id_mapped' lists with zeros to make each sequence length equal to the defined maximum sequence length.\n",
        "sessions['item_id_mapped'] = sessions['item_id_mapped'].apply(lambda x: [0] * (max_sequence_length - len(x)) + x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "t2fyxhKS2-SB",
        "outputId": "2c82e247-e0d6-44b3-f0a4-70ff47eff680"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_id_mapped</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[84, 85, 86, 92, 128961, 17454, 120640, 10840,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[101, 102, 103, 104, 105, 106, 107, 108, 109, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[117, 118, 119, 120, 121, 122, 123, 124, 125, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[169, 170, 171, 172, 174, 175, 176, 2819, 3131...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[205, 206, 207, 208, 209, 210, 211, 214, 218, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            item_id_mapped\n",
              "user_id                                                   \n",
              "8        [84, 85, 86, 92, 128961, 17454, 120640, 10840,...\n",
              "10       [101, 102, 103, 104, 105, 106, 107, 108, 109, ...\n",
              "11       [117, 118, 119, 120, 121, 122, 123, 124, 125, ...\n",
              "14       [169, 170, 171, 172, 174, 175, 176, 2819, 3131...\n",
              "17       [205, 206, 207, 208, 209, 210, 211, 214, 218, ..."
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first 5 rows of the DataFrame 'sessions'\n",
        "sessions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Common Argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the 'args' Namespace to store configuration and hyperparameters for the session-based recommendation model training.\n",
        "\n",
        "args = argparse.Namespace(\n",
        "    seed=seed,                             # Seed for reproducibility\n",
        "    save_path='./checkpoint/',             # Directory to save model checkpoints\n",
        "    model_name='best_model',               # Name of the best model checkpoint\n",
        "\n",
        "    device='cuda',                         # Device to use for training ('cuda' for GPU, 'cpu' for CPU)\n",
        "\n",
        "    is_parallel=False,                     # Flag to enable/disable model parallelism (multi-GPU training)\n",
        "\n",
        "    # get_data arguments\n",
        "    item_min=min_sequence_length,          # Minimum sequence length for a session\n",
        "    valid_rate=100,                        # Ratio of data samples to use for validation\n",
        "    max_len=max_sequence_length,           # Maximum allowed sequence length for a session\n",
        "    bert_mask_prob=0.3,                    # Probability for applying BERT-style masking to sequence data\n",
        "    pad_token=0,                           # Token value used for padding sequences\n",
        "    train_batch_size=32,                   # Batch size for training data\n",
        "    test_batch_size=32,                    # Batch size for testing data\n",
        "    val_batch_size=32,                     # Batch size for validation data\n",
        "\n",
        "    # load_model arguments\n",
        "    embedding_size=128,                   # Size of the item embedding vector\n",
        "    block_num=2,                          # Number of blocks in the model\n",
        "    dilations=[1, 4],                     # Dilation rates for the blocks\n",
        "    kernel_size=3,                        # Size of the convolutional kernel\n",
        "    num_items=num_items,                  # Number of unique items in the dataset\n",
        "    num_users=num_users,                  # Number of unique users in the dataset\n",
        "    num_heads=4,                          # Number of attention heads in the transformer\n",
        "    dropout=0.1,                          # Dropout rate for regularization\n",
        "\n",
        "    # SeqTrain arguments\n",
        "    epochs=20,                            # Number of training epochs\n",
        "    is_pretrain=1,                        # Flag for pretraining mode (0: pretrain, 1: train from scratch)\n",
        "    lr=0.0001,                            # Learning rate for optimization\n",
        "    weight_decay=0.0,                     # Weight decay regularization parameter\n",
        "    local_rank=None,                      # Local rank for distributed training\n",
        "    metric_ks=[1, 5, 10, 20],             # Values of 'k' for evaluating top-k metrics (e.g., top-1, top-5, etc.)\n",
        "    hidden_size=16,                       # Size of the hidden layer in the NextItNet model\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(args.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-B2alrG2-SB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW3nUOsq2-SB"
      },
      "source": [
        "## Train-Test-Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jjX2qoL2-SB",
        "outputId": "f7b3d61f-f618-404c-d9d6-33c2fd6699e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20020/20020 [00:00<00:00, 785492.80it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data, test_data = train_val_test_split(sessions['item_id_mapped'].apply(list).to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ZmUBhmKM2-SC"
      },
      "outputs": [],
      "source": [
        "# Split the train_data and val_data dictionaries into smaller subsets for session-based recommendation model validation.\n",
        "\n",
        "# Initialize empty dictionaries to store the smaller train and validation data subsets.\n",
        "train_data_s, val_data_s = {}, {}\n",
        "\n",
        "# Get the total number of data samples in the train_data dictionary.\n",
        "data_len = len(train_data)\n",
        "\n",
        "# Set up a loop to iterate over the keys (sessions) in the val_data dictionary.\n",
        "# The loop copies the session data from the original train_data and val_data dictionaries into the smaller subsets train_data_s and val_data_s.\n",
        "# The loop stops when a fraction of the data (specified by args.valid_rate) has been copied into the validation subset.\n",
        "\n",
        "i = 0\n",
        "for key, _ in val_data.items():\n",
        "    # Copy the session data from train_data into train_data_s.\n",
        "    train_data_s[key] = train_data[key]\n",
        "\n",
        "    # Copy the session data from val_data into val_data_s.\n",
        "    val_data_s[key] = val_data[key]\n",
        "\n",
        "    # Increment the counter 'i' to track the number of iterations.\n",
        "    i += 1\n",
        "\n",
        "    # Check if the number of iterations has reached the fraction of the total data specified by args.valid_rate.\n",
        "    # If it has, stop the loop to limit the size of the validation subset.\n",
        "    if i == int(data_len / args.valid_rate):\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-TIs3qSy2-SC"
      },
      "outputs": [],
      "source": [
        "# Create three datasets for session-based recommendation model training and evaluation.\n",
        "\n",
        "# 1. train_dataset:\n",
        "# The train_dataset is built using the BuildTrainDataset class, which constructs a training dataset from the train_data dictionary.\n",
        "# The training dataset includes input sequences (sessions) from train_data with a maximum length of args.max_len, padded with args.pad_token to reach the maximum length.\n",
        "# args.num_items represents the number of unique items in the dataset, which is used for encoding the item IDs.\n",
        "\n",
        "train_dataset = BuildTrainDataset(train_data, args.max_len, args.pad_token, args.num_items)\n",
        "\n",
        "# 2. valid_dataset:\n",
        "# The valid_dataset is constructed using the Build_full_EvalDataset class, which builds a full evaluation dataset from the train_data_s and val_data_s dictionaries.\n",
        "# The full evaluation dataset combines training and validation data, allowing evaluation on both datasets during model training.\n",
        "# The input sequences (sessions) from both train_data_s and val_data_s have a maximum length of args.max_len and are padded with args.pad_token to reach the maximum length.\n",
        "# args.num_items represents the number of unique items in the dataset, which is used for encoding the item IDs.\n",
        "\n",
        "valid_dataset = Build_full_EvalDataset(train_data_s, val_data_s, args.max_len, args.pad_token, args.num_items)\n",
        "\n",
        "# 3. test_dataset:\n",
        "# The test_dataset is created using the Build_full_EvalDataset class, which builds a full evaluation dataset from the train_data and test_data dictionaries.\n",
        "# Similar to the valid_dataset, the full evaluation dataset combines training and testing data to allow evaluation on both datasets after model training.\n",
        "# The input sequences (sessions) from both train_data and test_data have a maximum length of args.max_len and are padded with args.pad_token to reach the maximum length.\n",
        "# args.num_items represents the number of unique items in the dataset, which is used for encoding the item IDs.\n",
        "\n",
        "test_dataset = Build_full_EvalDataset(train_data, test_data, args.max_len, args.pad_token, args.num_items)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TvgVeMBP2-SC"
      },
      "outputs": [],
      "source": [
        "# Create three data loaders for the session-based recommendation model training and evaluation.\n",
        "\n",
        "# 1. train_dataloader:\n",
        "# The train_dataloader is created using the get_train_loader function, which generates a data loader for the train_dataset.\n",
        "# The train_dataset contains training samples that are organized in batches to facilitate efficient model training.\n",
        "# The get_train_loader function handles batch creation, taking into account the training batch size specified in args.train_batch_size.\n",
        "\n",
        "train_dataloader = get_train_loader(train_dataset, args)\n",
        "\n",
        "# 2. valid_dataloader:\n",
        "# The valid_dataloader is generated using the get_val_loader function, which creates a data loader for the valid_dataset.\n",
        "# The valid_dataset includes a combination of training and validation data, used for model validation during training.\n",
        "# Similar to the train_dataloader, the get_val_loader function manages batch creation, considering the validation batch size specified in args.val_batch_size.\n",
        "\n",
        "valid_dataloader = get_val_loader(valid_dataset, args)\n",
        "\n",
        "# 3. test_dataloader:\n",
        "# The test_dataloader is constructed using the get_test_loader function, which generates a data loader for the test_dataset.\n",
        "# The test_dataset combines training and testing data, facilitating model evaluation on both datasets after training.\n",
        "# Like the previous dataloaders, the get_test_loader function handles batch creation, considering the test batch size specified in args.test_batch_size.\n",
        "\n",
        "test_dataloader = get_test_loader(test_dataset, args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- We chose the NextItNet model out of four candidate models (GRU4Rec, BERT4Rec, SASRec, and NextItNet) based on their performance in terms of the NDCG@20 evaluation metric.\n",
        "- We conducted experiments on two different datasets: one containing users with age 3 and the other containing users with age 0.\n",
        "\n",
        "The NDCG@20 results for each model on the respective datasets are as follows:\n",
        "\n",
        "| Model | NDCG@20 for users with age 3 | NDCG@20 for users with age 0 |\n",
        "| --- | --- | ---|\n",
        "| NextItNet| 0.0111 | 0.0081 |\n",
        "| SASRec | 0.0103 | 0.0079 |\n",
        "| GRU4Rec | 0.0100 | 0.0058 |\n",
        "| BERTModel | 7.7849e-05 | 1.1388e-05 |\n",
        "\n",
        "Based on the comparison of NDCG@20 values, the NextItNet model achieved the highest performance for both user groups, demonstrating its superiority in capturing and leveraging sequential patterns for session-based recommendation tasks. Thus, NextItNet was chosen as the best model for this particular recommendation scenario.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk6O3uCp2-SC"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sdC3wpHu2-SD"
      },
      "outputs": [],
      "source": [
        "# Instantiate the NextItNet model with the provided configuration and hyperparameters.\n",
        "model = NextItNet(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXK5hBSJ2-SD"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ex9R-GF2-SD",
        "outputId": "ebdf26ee-a10d-435b-9a92-0c48a0a79a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++ Train Epoch 1 ++++++++++++++++++++\n",
            "Training CE Loss: 11.55141\n",
            "one epoch train: 50.90104794502258\n",
            "++++++++++++++++++++ Valid Epoch 1 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0071, device='cuda:0'), 'Recall@10': 0.008928571428571428, 'NDCG@10': tensor(0.0059, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.117779493331909\n",
            "++++++++++++++++++++ Train Epoch 2 ++++++++++++++++++++\n",
            "Training CE Loss: 10.60392\n",
            "one epoch train: 55.35017681121826\n",
            "++++++++++++++++++++ Valid Epoch 2 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0058, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0058, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0028, device='cuda:0'), 'Recall@1': 0.0, 'NDCG@1': tensor(0., device='cuda:0')}\n",
            "one epoch val: 3.12445330619812\n",
            "++++++++++++++++++++ Train Epoch 3 ++++++++++++++++++++\n",
            "Training CE Loss: 10.38311\n",
            "one epoch train: 58.37707567214966\n",
            "++++++++++++++++++++ Valid Epoch 3 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0055, device='cuda:0'), 'Recall@10': 0.008928571428571428, 'NDCG@10': tensor(0.0043, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0028, device='cuda:0'), 'Recall@1': 0.0, 'NDCG@1': tensor(0., device='cuda:0')}\n",
            "one epoch val: 2.980158805847168\n",
            "++++++++++++++++++++ Train Epoch 4 ++++++++++++++++++++\n",
            "Training CE Loss: 10.19755\n",
            "one epoch train: 54.145509481430054\n",
            "++++++++++++++++++++ Valid Epoch 4 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0077, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0077, device='cuda:0'), 'Recall@5': 0.008928571428571428, 'NDCG@5': tensor(0.0062, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.9572057723999023\n",
            "++++++++++++++++++++ Train Epoch 5 ++++++++++++++++++++\n",
            "Training CE Loss: 10.01112\n",
            "one epoch train: 56.52671933174133\n",
            "++++++++++++++++++++ Valid Epoch 5 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0071, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.016868829727173\n",
            "++++++++++++++++++++ Train Epoch 6 ++++++++++++++++++++\n",
            "Training CE Loss: 9.81716\n",
            "one epoch train: 61.675681829452515\n",
            "++++++++++++++++++++ Valid Epoch 6 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0071, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.9750499725341797\n",
            "++++++++++++++++++++ Train Epoch 7 ++++++++++++++++++++\n",
            "Training CE Loss: 9.61347\n",
            "one epoch train: 54.09491801261902\n",
            "++++++++++++++++++++ Valid Epoch 7 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0071, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.980618476867676\n",
            "++++++++++++++++++++ Train Epoch 8 ++++++++++++++++++++\n",
            "Training CE Loss: 9.39714\n",
            "one epoch train: 54.30453824996948\n",
            "++++++++++++++++++++ Valid Epoch 8 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0071, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.0188772678375244\n",
            "++++++++++++++++++++ Train Epoch 9 ++++++++++++++++++++\n",
            "Training CE Loss: 9.16482\n",
            "one epoch train: 54.19940757751465\n",
            "++++++++++++++++++++ Valid Epoch 9 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0082, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.9972171783447266\n",
            "++++++++++++++++++++ Train Epoch 10 ++++++++++++++++++++\n",
            "Training CE Loss: 8.91000\n",
            "one epoch train: 54.048725605010986\n",
            "++++++++++++++++++++ Valid Epoch 10 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0081, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.0428504943847656\n",
            "++++++++++++++++++++ Train Epoch 11 ++++++++++++++++++++\n",
            "Training CE Loss: 8.62678\n",
            "one epoch train: 54.531245708465576\n",
            "++++++++++++++++++++ Valid Epoch 11 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0081, device='cuda:0'), 'Recall@10': 0.008928571428571428, 'NDCG@10': tensor(0.0058, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.01629900932312\n",
            "++++++++++++++++++++ Train Epoch 12 ++++++++++++++++++++\n",
            "Training CE Loss: 8.32358\n",
            "one epoch train: 53.86487603187561\n",
            "++++++++++++++++++++ Valid Epoch 12 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0080, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.984069347381592\n",
            "++++++++++++++++++++ Train Epoch 13 ++++++++++++++++++++\n",
            "Training CE Loss: 8.00703\n",
            "one epoch train: 54.015385389328\n",
            "++++++++++++++++++++ Valid Epoch 13 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0080, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.0937561988830566\n",
            "++++++++++++++++++++ Train Epoch 14 ++++++++++++++++++++\n",
            "Training CE Loss: 7.67901\n",
            "one epoch train: 54.06657361984253\n",
            "++++++++++++++++++++ Valid Epoch 14 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0082, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 2.980431318283081\n",
            "++++++++++++++++++++ Train Epoch 15 ++++++++++++++++++++\n",
            "Training CE Loss: 7.33780\n",
            "one epoch train: 53.95038104057312\n",
            "++++++++++++++++++++ Valid Epoch 15 ++++++++++++++++++++\n",
            "{'Recall@20': 0.022321428571428572, 'NDCG@20': tensor(0.0094, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.069464921951294\n",
            "++++++++++++++++++++ Train Epoch 16 ++++++++++++++++++++\n",
            "Training CE Loss: 6.98801\n",
            "one epoch train: 53.974621534347534\n",
            "++++++++++++++++++++ Valid Epoch 16 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0080, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.027787208557129\n",
            "++++++++++++++++++++ Train Epoch 17 ++++++++++++++++++++\n",
            "Training CE Loss: 6.63580\n",
            "one epoch train: 53.91797590255737\n",
            "++++++++++++++++++++ Valid Epoch 17 ++++++++++++++++++++\n",
            "{'Recall@20': 0.022321428571428572, 'NDCG@20': tensor(0.0092, device='cuda:0'), 'Recall@10': 0.013392857142857142, 'NDCG@10': tensor(0.0070, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.073399305343628\n",
            "++++++++++++++++++++ Train Epoch 18 ++++++++++++++++++++\n",
            "Training CE Loss: 6.29297\n",
            "one epoch train: 53.97878170013428\n",
            "++++++++++++++++++++ Valid Epoch 18 ++++++++++++++++++++\n",
            "{'Recall@20': 0.013392857142857142, 'NDCG@20': tensor(0.0069, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.016883373260498\n",
            "++++++++++++++++++++ Train Epoch 19 ++++++++++++++++++++\n",
            "Training CE Loss: 5.97053\n",
            "one epoch train: 54.07042336463928\n",
            "++++++++++++++++++++ Valid Epoch 19 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0080, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.046058177947998\n",
            "++++++++++++++++++++ Train Epoch 20 ++++++++++++++++++++\n",
            "Training CE Loss: 5.67857\n",
            "one epoch train: 54.02807402610779\n",
            "++++++++++++++++++++ Valid Epoch 20 ++++++++++++++++++++\n",
            "{'Recall@20': 0.017857142857142856, 'NDCG@20': tensor(0.0080, device='cuda:0'), 'Recall@10': 0.004464285714285714, 'NDCG@10': tensor(0.0045, device='cuda:0'), 'Recall@5': 0.004464285714285714, 'NDCG@5': tensor(0.0045, device='cuda:0'), 'Recall@1': 0.004464285714285714, 'NDCG@1': tensor(0.0045, device='cuda:0')}\n",
            "one epoch val: 3.015411615371704\n",
            "train_time: 1094.0221388339996\n",
            "val_time: 60.534640073776245\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "NextItNet(\n",
              "  (item_embedding): Embedding(216556, 128, padding_idx=0)\n",
              "  (residual_blocks): Sequential(\n",
              "    (0): ResidualBlock_b(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1))\n",
              "      (ln1): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))\n",
              "      (ln2): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "    )\n",
              "    (1): ResidualBlock_b(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(4, 4))\n",
              "      (ln1): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(8, 8))\n",
              "      (ln2): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "    )\n",
              "    (2): ResidualBlock_b(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1))\n",
              "      (ln1): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(2, 2))\n",
              "      (ln2): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "    )\n",
              "    (3): ResidualBlock_b(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(4, 4))\n",
              "      (ln1): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(1, 3), stride=(1, 1), dilation=(8, 8))\n",
              "      (ln2): LayerNorm((128,), eps=1e-08, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (final_layer): Linear(in_features=128, out_features=216556, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform training and validation using the SeqTrain function with the specified configuration and hyperparameters.\n",
        "SeqTrain(args.epochs, model, train_dataloader, valid_dataloader, writer, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqPByQG92-SD"
      },
      "source": [
        "#### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++ Valid Epoch 1 ++++++++++++++++++++\n",
            "{'Recall@20': 0.023911741214057508, 'NDCG@20': tensor(0.0094, device='cuda:0'), 'Recall@10': 0.014776357827476038, 'NDCG@10': tensor(0.0071, device='cuda:0'), 'Recall@5': 0.008536341853035144, 'NDCG@5': tensor(0.0051, device='cuda:0'), 'Recall@1': 0.0017971246006389776, 'NDCG@1': tensor(0.0018, device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "# Load the best-performing model weights from the saved checkpoint file.\n",
        "\n",
        "# The 'best_weight' variable is used to load the model weights from a specified checkpoint file. The file path is constructed based on the provided configuration and hyperparameters (args) to ensure the correct checkpoint file is loaded.\n",
        "\n",
        "best_weight = torch.load(os.path.join(args.save_path, f'{args.model_name}_seed{args.seed}_is_pretrain_{args.is_pretrain}_best_model_lr{args.lr}_wd{args.weight_decay}_block{args.block_num}_hd{args.hidden_size}_emb{args.embedding_size}.pth'))\n",
        "\n",
        "# Load the model's state dictionary with the loaded best weights.\n",
        "\n",
        "# The model's state dictionary is updated with the best weights, effectively loading the best-performing model configuration.\n",
        "\n",
        "model.load_state_dict(best_weight)\n",
        "\n",
        "# Move the model to the specified device (GPU or CPU).\n",
        "\n",
        "# The 'model' is moved to the device specified in args.device, allowing computations and predictions to be performed on the chosen device.\n",
        "\n",
        "model = model.to(args.device)\n",
        "\n",
        "# Perform full sequence validation on the test dataset.\n",
        "\n",
        "# The Sequence_full_Validate function is called to evaluate the model's performance on the test dataset (test_dataloader).\n",
        "# The function takes the provided model, performs sequence validation, and logs relevant evaluation metrics using the specified SummaryWriter (writer) for TensorBoard.\n",
        "\n",
        "metrics = Sequence_full_Validate(0, model, test_dataloader, writer, args, test=True)\n",
        "\n",
        "# Close the SummaryWriter.\n",
        "\n",
        "# The SummaryWriter is closed to finish logging the training and evaluation metrics for TensorBoard visualization and monitoring.\n",
        "\n",
        "writer.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\n",
        "\n",
        "- The best model we utilized for session-based recommendation is the NextItNet architecture. This model demonstrated superior performance compared to other models, including GRU4Rec, BERT4Rec, and SASRec, on two distinct datasets representing users with age 3 and users with age 0. The comparison revealed that NextItNet consistently achieved higher NDCG@20 values, indicating its effectiveness in capturing sequential patterns and recommending relevant items to users.\n",
        "\n",
        "- The NextItNet architecture consists of an item embedding layer followed by a series of residual blocks. Each residual block comprises two convolutional layers with different dilation rates and layer normalization. The model's final layer is a linear transformation responsible for predicting the item's likelihood for each user.\n",
        "\n",
        "- During the training process, we observed a gradual reduction in the cross-entropy loss, indicating that the model learned from the data effectively. However, it is worth noting that the validation NDCG@20 score remained relatively stable throughout the training epochs, hovering around 0.0080. This observation suggests that the model might have reached a point of convergence and might not be improving significantly with additional training epochs.\n",
        "\n",
        "- Upon evaluation on a separate test dataset, the NextItNet model achieved an NDCG@20 score of approximately 0.0094. This result reaffirms the model's capability to generalize well to unseen data and users with age values of 0 and 3.\n",
        "\n",
        "- The NextItNet model's strengths lie in its ability to capture complex temporal dependencies in user-item interactions, allowing it to provide personalized recommendations for each session effectively. Additionally, the model's architecture is more lightweight compared to other candidate models, making it computationally efficient.\n",
        "\n",
        "- However, one potential limitation of the NextItNet model is that its performance plateaued after a certain number of training epochs, indicating the possibility of overfitting on the training data. Fine-tuning the hyperparameters, such as the learning rate and weight decay, might be necessary to achieve better generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtlrSbjX2-SD"
      },
      "source": [
        "## Conclusion\n",
        "- The NextItNet model demonstrated exceptional performance in the session-based recommendation task, outperforming other models across different user age groups. Its ability to generalize well to unseen data and users further underscores its potential for real-world recommendation systems. However, further research and experimentation are required to fine-tune the model and optimize its hyperparameters for even better performance. The NextItNet model remains a promising solution for session-based recommendation tasks and merits further investigation in practical recommendation scenarios."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
